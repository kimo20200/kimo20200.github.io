<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#57b5e7"><meta name="author" content="霂水流年"><meta name="copyright" content="霂水流年"><meta name="generator" content="Hexo 4.2.0"><meta name="theme" content="hexo-theme-yun"><title>Tensor[Pytorch][2] | 心记</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="none" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.15/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_stqaphw3j4.js" async></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>document.addEventListener("DOMContentLoaded", () => {
  [".post-card",".post-content img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
});
</script><link rel="shortcut icon" type="image/svg+xml" href="/favicon.ico"><link rel="mask-icon" href="/favicon.ico" color="#57b5e7"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script id="yun-config">
    const Yun = window.Yun || {};
    window.CONFIG = {"root":"/","title":"徐先生的梦境","version":"0.9.3","anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"local_search":{"path":"/search.xml"},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><meta name="description" content="全力全開">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensor[Pytorch][2]">
<meta property="og:url" content="http://yoursite.com/2020/08/15/DL_P7/index.html">
<meta property="og:site_name" content="心记">
<meta property="og:description" content="全力全開">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-08-15T09:09:31.708Z">
<meta property="article:modified_time" content="2020-08-15T09:06:35.116Z">
<meta property="article:author" content="霂水流年">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary"></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script defer src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="霂水流年"><img width="96" loading="lazy" src="/xu.jpg" alt="霂水流年"></a><div class="site-author-name"><a href="/about/">霂水流年</a></div><a class="site-name" href="/about/site.html">心记</a><sub class="site-subtitle"></sub><div class="site-desciption">关关雎鸠，在河之洲</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="我的主页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">10</span></a></div><div class="site-state-item"><a href="/categories/" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">2</span></a></div><div class="site-state-item"><a href="/tags/" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">2</span></a></div><a class="site-state-item hty-icon-button" href="https://yun.yunyoujun.cn" target="_blank" rel="noopener" title="文档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-settings-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/xq14183903" title="GitHub" target="_blank" style="color:#6e5494"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://music.163.com/#/user/home?id=94624423" title="网易云音乐" target="_blank" style="color:#C20C0C"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-netease-cloud-music-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.zhihu.com/people/mu-shui-liu-nian-26" title="知乎" target="_blank" style="color:#0084FF"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhihu-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/6023987" title="哔哩哔哩" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:xq14183903@outlook.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="https://wwwwww537.github.io" target="_blank" rel="noopener" title="我的小伙伴们" style="color:dodgerblue"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a></div></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#Tensor的索引与变形"><span class="toc-number">1.</span> <span class="toc-text">Tensor的索引与变形</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Tensor的排序与取极值"><span class="toc-number">2.</span> <span class="toc-text">Tensor的排序与取极值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Tensor的自动广播机制"><span class="toc-number">3.</span> <span class="toc-text">Tensor的自动广播机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Tensor的内存共享和转换"><span class="toc-number">4.</span> <span class="toc-text">Tensor的内存共享和转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Reference"><span class="toc-number">5.</span> <span class="toc-text">Reference</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/15/DL_P7/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="霂水流年"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="心记"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Tensor[Pytorch][2]</h1><div class="post-meta"><div class="post-time" style="display:inline-block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <span class="post-meta-icon-text">发表于</span> <time title="创建时间：2020-08-15 17:09:31" itemprop="dateCreated datePublished" datetime="2020-08-15T17:09:31+08:00">2020-08-15</time></div><span class="post-busuanzi"><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读次数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg> <span id="busuanzi_value_page_pv"></span></span></span><div class="post-classify"><span class="post-category"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span> <span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Win10-%E5%AE%9E%E6%88%98/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">从零开始的深度学习[Win10][实战]</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">深度学习</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#57b5e7;"><h4 id="Tensor的索引与变形"><a href="#Tensor的索引与变形" class="headerlink" title="Tensor的索引与变形"></a>Tensor的索引与变形</h4><p>先行变量：<code>a = torch.Tensor([[0,1],[2,3]])</code></p>
<ol>
<li>根据下标进行索引（类似数组索引）<br>例：<code>a[0]</code>, <code>a[0,1]</code></li>
<li>设置条件对tensor内的元素进行判断，符合条件的置True，否则置False<br>例：<code>b = a &gt; 1</code></li>
<li>选择符合条件的元素并返回<br>例：<code>a[a &gt; 1]</code></li>
<li>选择非0元素的坐标，并返回<br><code>torch.nonzero()</code></li>
<li>满足condition的位置输出x，否则输出y<br><code>torch.where(condition, torch.full_like(input, x), y)</code></li>
<li>限制Tensor元素在[x, y]范围内，小于x的元素被设置成x，大于y的元素被设置成y，其余的不变<br><code>input.clamp(x, y)</code></li>
<li>view()、resize()和reshape()函数可以在不改变Tensor数据的前提下任意改变Tensor的形状，必须保证调整前后的元素总数相同，并且调整前后共享内存，三者的作用基本相同。<br>例：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">a &#x3D; torch.Tensor([[0,1],[2,3]])</span><br><span class="line">print(a.view(1,4)) </span><br><span class="line">print(a.resize(2,2))</span><br><span class="line">print(a.reshape(4,1))</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">result:</span><br><span class="line"></span><br><span class="line">tensor([[0., 1., 2., 3.]])</span><br><span class="line">tensor([[0., 1.],</span><br><span class="line">        [2., 3.]])</span><br><span class="line">tensor([[0.],</span><br><span class="line">        [1.],</span><br><span class="line">        [2.],</span><br><span class="line">        [3.]])</span><br><span class="line">&#39;&#39;&#39;</span><br></pre></td></tr></table></figure></li>
<li>transpose()函数可以将指定的两个维度的元素进行转置，而permute()函数则可以按照给定的维度进行维度变换。<br>例：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">a &#x3D; torch.Tensor([[0,1],[2,3]])</span><br><span class="line">print(a)</span><br><span class="line">print(a.transpose(0,1))</span><br><span class="line">print(a.permute(1,0))</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">result:</span><br><span class="line"></span><br><span class="line">tensor([[0., 1.],</span><br><span class="line">        [2., 3.]])</span><br><span class="line">tensor([[0., 2.],</span><br><span class="line">        [1., 3.]])</span><br><span class="line">tensor([[0., 2.],</span><br><span class="line">        [1., 3.]])</span><br><span class="line">&#39;&#39;&#39;</span><br></pre></td></tr></table></figure></li>
<li>使用squeeze()与unsqueeze()函数，前者用于去除size为1的维度，而后者则是将指定的维度的size变为1。<br>例：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">a &#x3D; torch.Tensor([[0,1],[2,3]])</span><br><span class="line">print(a)</span><br><span class="line">print(a.unsqueeze(2))</span><br><span class="line">print(a.unsqueeze(2).squeeze(2))</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">result:</span><br><span class="line"></span><br><span class="line">tensor([[0., 1.],</span><br><span class="line">        [2., 3.]])</span><br><span class="line">tensor([[[0.],</span><br><span class="line">         [1.]],</span><br><span class="line"></span><br><span class="line">        [[2.],</span><br><span class="line">         [3.]]])</span><br><span class="line">tensor([[0., 1.],</span><br><span class="line">        [2., 3.]])</span><br><span class="line">&#39;&#39;&#39;</span><br></pre></td></tr></table></figure></li>
<li>expand()函数将size为1的维度复制扩展为指定大小，也可以使用expand_as()函数指定为示例Tensor的维度。<br>例：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">a &#x3D; torch.Tensor([[0],[3]])</span><br><span class="line">print(a)</span><br><span class="line">print(a.expand(2,4))</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">result:</span><br><span class="line"></span><br><span class="line">tensor([[0.],</span><br><span class="line">        [3.]])</span><br><span class="line">tensor([[0., 0., 0., 0.],</span><br><span class="line">        [3., 3., 3., 3.]])</span><br><span class="line">&#39;&#39;&#39;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="Tensor的排序与取极值"><a href="#Tensor的排序与取极值" class="headerlink" title="Tensor的排序与取极值"></a>Tensor的排序与取极值</h4><ol>
<li>函数sort()，选择沿着指定维度进行排序，返回排序后的Tensor及对应的索引位置。<br>例：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">a &#x3D; torch.randn(3,3)</span><br><span class="line">print(a)</span><br><span class="line"># 按照第0维进行按列排序，True代表降序，False代表升序</span><br><span class="line">print(a.sort(0,True))</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">result:</span><br><span class="line"></span><br><span class="line">tensor([[ 0.6448,  0.5900,  2.2122],</span><br><span class="line">        [ 0.1974,  2.0291, -0.1883],</span><br><span class="line">        [-0.6540, -1.2901,  0.8186]])</span><br><span class="line">torch.return_types.sort(</span><br><span class="line">values&#x3D;tensor([[ 0.6448,  2.0291,  2.2122],</span><br><span class="line">               [ 0.1974,  0.5900,  0.8186],</span><br><span class="line">               [-0.6540, -1.2901, -0.1883]]),</span><br><span class="line">indices&#x3D;tensor([[0, 1, 0],</span><br><span class="line">                [1, 0, 2],</span><br><span class="line">                [2, 2, 1]]))</span><br></pre></td></tr></table></figure></li>
<li>max()与min()函数则是沿着指定维度选择最大与最小元素，返回该元素及对应的索引位置。<br>例：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">a &#x3D; torch.randn(3,3)</span><br><span class="line">print(a)</span><br><span class="line"># 选出每一列的最大值</span><br><span class="line">print(a.max(0))</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">result:</span><br><span class="line"></span><br><span class="line">tensor([[ 0.8609,  2.1089,  0.5477],</span><br><span class="line">        [-0.7530,  0.6850, -0.9778],</span><br><span class="line">        [-2.0674,  0.6929,  1.4075]])</span><br><span class="line">torch.return_types.max(</span><br><span class="line">values&#x3D;tensor([0.8609, 2.1089, 1.4075]),</span><br><span class="line">indices&#x3D;tensor([0, 0, 2]))</span><br><span class="line">&#39;&#39;&#39;</span><br></pre></td></tr></table></figure>
<h4 id="Tensor的自动广播机制"><a href="#Tensor的自动广播机制" class="headerlink" title="Tensor的自动广播机制"></a>Tensor的自动广播机制</h4>不同形状的Tensor进行计算时，可自动扩展到较大的相同形状，再进行计算。广播机制的前提是任一个Tensor至少有一个维度，且从尾部遍历Tensor维度时，两者维度必须相等，其中一个要么是1要么不存在。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">a &#x3D; torch.ones(3,1,2)</span><br><span class="line">b &#x3D; torch.ones(3,1)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br><span class="line"># 从尾部遍历维度，1对应3，2对应1，3对应不存在，因此满足广播条件，最后求和后的维度为[3,3,2]</span><br><span class="line">print(a+b)</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">result:</span><br><span class="line"></span><br><span class="line">tensor([[[1., 1.]],</span><br><span class="line"></span><br><span class="line">        [[1., 1.]],</span><br><span class="line"></span><br><span class="line">        [[1., 1.]]])</span><br><span class="line">tensor([[1.],</span><br><span class="line">        [1.],</span><br><span class="line">        [1.]])</span><br><span class="line">tensor([[[2., 2.],</span><br><span class="line">         [2., 2.],</span><br><span class="line">         [2., 2.]],</span><br><span class="line"></span><br><span class="line">        [[2., 2.],</span><br><span class="line">         [2., 2.],</span><br><span class="line">         [2., 2.]],</span><br><span class="line"></span><br><span class="line">        [[2., 2.],</span><br><span class="line">         [2., 2.],</span><br><span class="line">         [2., 2.]]])</span><br><span class="line">&#39;&#39;&#39;</span><br></pre></td></tr></table></figure>
<h4 id="Tensor的内存共享和转换"><a href="#Tensor的内存共享和转换" class="headerlink" title="Tensor的内存共享和转换"></a>Tensor的内存共享和转换</h4></li>
<li>原地操作符<br>PyTorch对于一些操作通过加后缀“<em>”实现了原地操作，如add</em>()和resize_()等，这种操作只要被执行，本身的Tensor则会被改变。<br>例：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">a &#x3D; torch.ones(2,2)</span><br><span class="line">print(a)</span><br><span class="line">a.add_(a)</span><br><span class="line">print(a)</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">result:</span><br><span class="line"></span><br><span class="line">tensor([[1., 1.],</span><br><span class="line">        [1., 1.]])</span><br><span class="line">tensor([[2., 2.],</span><br><span class="line">        [2., 2.]])</span><br><span class="line">&#39;&#39;&#39;</span><br></pre></td></tr></table></figure></li>
<li>Tensor与NumPy转换<br>Tensor与NumPy可以高效地进行转换，并且转换前后的变量共享内存。在进行PyTorch不支持的操作时，甚至可以曲线救国，将Tensor转换为NumPy类型，操作后再转为Tensor。<br>例：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">a &#x3D; torch.ones(2,2)</span><br><span class="line"># 转numpy</span><br><span class="line">b &#x3D; a.numpy()  </span><br><span class="line"># 转tensor</span><br><span class="line">c &#x3D; torch.from_numpy(b)</span><br><span class="line"># 转list</span><br><span class="line">d &#x3D; a.tolist()</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br><span class="line">print(c)</span><br><span class="line">print(d)</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">result:</span><br><span class="line"></span><br><span class="line">tensor([[1., 1.],</span><br><span class="line">        [1., 1.]])</span><br><span class="line"></span><br><span class="line">        [[1. 1.]</span><br><span class="line">        [1. 1.]]</span><br><span class="line"></span><br><span class="line">tensor([[1., 1.],</span><br><span class="line">        [1., 1.]])</span><br><span class="line"></span><br><span class="line">[[1.0, 1.0], [1.0, 1.0]]</span><br><span class="line">&#39;&#39;&#39;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><blockquote>
<p>深度学习之PyTorch物体检测实战 - 董洪义</p>
</blockquote>
</div><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="打赏" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span><div id="reward-comment">money money money~ money money~</div><div id="qr" style="display:none;"><div style="display:inline-block"><a href="/alipay.jpg"><img loading="lazy" src="/alipay.jpg" alt="支付宝" title="支付宝"></a><div><span style="color:#00A3EE"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-alipay-line"></use></svg></span></div></div><div style="display:inline-block"><a href="/wechat.png"><img loading="lazy" src="/wechat.png" alt="微信支付" title="微信支付"></a><div><span style="color:#2DC100"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-pay-line"></use></svg></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>霂水流年</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="http://yoursite.com/2020/08/15/DL_P7/" title="Tensor[Pytorch][2]">http://yoursite.com/2020/08/15/DL_P7/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> 许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2020/08/17/DL_P8/" rel="prev" title="Tensor[Pytorch][3]"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">Tensor[Pytorch][3]</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2020/08/14/DL_P6/" rel="next" title="Tensor[Pytorch][1]"><span class="post-nav-text">Tensor[Pytorch][1]</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div id="comment"><div class="comment-tooltip text-center"><span>点击按钮跳转 GitHub Issues 评论。</span><br><span>若没有本文 Issue，您可以使用 Comment 模版新建。</span><br><a class="hty-button hty-button--raised" id="github-issues" href="https://github.com/xq14183903/xq14183903.github.io/issues?q=is:issue+Tensor[Pytorch][2]" target="_blank" rel="noopener">GitHub Issues</a></div><div id="valine-container"></div><script src="https://cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script><script>function initValine() {
  const valineConfig = {"enable":true,"appId":"lhezWYEOlfT1JUENiOuMhXeA-gzGzoHsz","appKey":"xJsej5fqNjpWVaosFeW83nex","placeholder":"Say anything you want","avatar":null,"pageSize":10,"visitor":false,"highlight":true,"recordIP":true,"enableQQ":true,"el":"#valine-container","lang":"zh-cn"}
  valineConfig.path = window.location.pathname
  new Valine(valineConfig)
}
setTimeout(initValine, 1000)</script></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2020 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> 霂水流年</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v4.2.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v0.9.3</span></div><div id="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv" title="总访客量"><span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-user-line"></use></svg></span><span id="busuanzi_value_site_uv"></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv" title="总访问量"><span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg></span><span id="busuanzi_value_site_pv"></span></span></div></footer><a class="hty-icon-button" id="goUp" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#57b5e7" stroke-width="2" stroke-linecap="round"></circle></svg></a><a class="popup-trigger hty-icon-button icon-search" id="search" href="javascript:;" title="搜索"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-search-line"></use></svg></span></a><script>window.addEventListener("DOMContentLoaded", () => {
  // Handle and trigger popup window
  document.querySelector(".popup-trigger").addEventListener("click", () => {
    document.querySelector(".popup").classList.add("show");
    setTimeout(() => {
      document.querySelector(".search-input").focus();
    }, 100);
  });

  // Monitor main search box
  const onPopupClose = () => {
    document.querySelector(".popup").classList.remove("show");
  };

  document.querySelector(".popup-btn-close").addEventListener("click", () => {
    onPopupClose();
  });

  window.addEventListener("keyup", event => {
    if (event.key === "Escape") {
      onPopupClose();
    }
  });
});
</script><script src="/js/search/local-search.js" defer></script><div class="popup search-popup"><div class="search-header"><span class="popup-btn-close close-icon hty-icon-button"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-close-line"></use></svg></span></div><div class="search-input-container"><input class="search-input" id="local-search-input" type="text" placeholder="搜索..." value=""></div><div id="local-search-result"></div></div></div><script defer src="/js/utils.js"></script><script defer src="/js/hexo-theme-yun.js"></script></body></html>